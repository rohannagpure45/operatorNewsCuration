"""Pydantic models for structured data in the News Curation Agent."""

from datetime import datetime, timezone
from enum import Enum
from typing import List, Optional

from pydantic import BaseModel, Field, HttpUrl


class URLType(str, Enum):
    """Supported URL types for content extraction."""

    TWITTER = "twitter"
    NEWS_ARTICLE = "news_article"
    BLOG = "blog"
    SEC_FILING = "sec_filing"
    UNKNOWN = "unknown"


class Sentiment(str, Enum):
    """Sentiment classification for content."""

    POSITIVE = "positive"
    NEGATIVE = "negative"
    NEUTRAL = "neutral"
    MIXED = "mixed"


class EntityType(str, Enum):
    """Types of named entities."""

    PERSON = "PERSON"
    ORGANIZATION = "ORG"
    LOCATION = "LOC"
    DATE = "DATE"
    MONEY = "MONEY"
    PRODUCT = "PRODUCT"
    EVENT = "EVENT"


class Entity(BaseModel):
    """A named entity extracted from content."""

    text: str = Field(description="The entity text as it appears in the content")
    type: EntityType = Field(description="The type of entity")
    relevance: Optional[float] = Field(
        default=None, ge=0.0, le=1.0, description="Relevance score (0-1)"
    )


class Footnote(BaseModel):
    """A footnote with source attribution."""

    id: int = Field(description="Footnote reference number")
    source_text: str = Field(description="The quoted or referenced text")
    context: str = Field(description="Additional context or explanation")


class ClaimRating(str, Enum):
    """Rating levels for fact-checked claims."""

    TRUE = "true"
    MOSTLY_TRUE = "mostly_true"
    MIXED = "mixed"
    MOSTLY_FALSE = "mostly_false"
    FALSE = "false"
    UNVERIFIED = "unverified"
    INSUFFICIENT_DATA = "insufficient_data"


class FactCheckResult(BaseModel):
    """Result of fact-checking a specific claim."""

    claim: str = Field(description="The claim that was fact-checked")
    rating: ClaimRating = Field(description="The fact-check rating")
    source: str = Field(description="The fact-checking organization")
    source_url: Optional[str] = Field(
        default=None, description="URL to the fact-check article"
    )
    explanation: Optional[str] = Field(
        default=None, description="Brief explanation of the rating"
    )
    reviewed_date: Optional[datetime] = Field(
        default=None, description="When the claim was reviewed"
    )


class PublisherCredibility(BaseModel):
    """Publisher credibility information."""

    score: Optional[int] = Field(
        default=None, ge=0, le=100, description="Credibility score (0-100)"
    )
    source: str = Field(description="Source of the credibility rating")
    notes: Optional[str] = Field(default=None, description="Additional notes")


class FactCheckReport(BaseModel):
    """Complete fact-check report for content."""

    claims_analyzed: int = Field(
        default=0, description="Number of claims analyzed"
    )
    verified_claims: List[FactCheckResult] = Field(
        default_factory=list, description="Claims that were verified"
    )
    unverified_claims: List[str] = Field(
        default_factory=list, description="Claims that couldn't be verified"
    )
    publisher_credibility: Optional[PublisherCredibility] = Field(
        default=None, description="Publisher credibility information"
    )


class ContentSummary(BaseModel):
    """Structured summary of content generated by LLM."""

    executive_summary: str = Field(
        description="One paragraph overview of the content"
    )
    key_points: List[str] = Field(
        min_length=1,
        max_length=10,
        description="Main takeaways from the content (3-7 points)",
    )
    sentiment: Sentiment = Field(description="Overall sentiment of the content")
    entities: List[Entity] = Field(
        default_factory=list, description="Key named entities mentioned"
    )
    implications: List[str] = Field(
        default_factory=list,
        description="Potential implications or impacts discussed",
    )
    footnotes: List[Footnote] = Field(
        default_factory=list, description="Notable quotes or citations"
    )
    topics: List[str] = Field(
        default_factory=list, description="Main topics/themes covered"
    )


class ContentMetadata(BaseModel):
    """Metadata about the extracted content."""

    title: Optional[str] = Field(default=None, description="Content title")
    author: Optional[str] = Field(default=None, description="Author name")
    published_date: Optional[datetime] = Field(
        default=None, description="Publication date"
    )
    word_count: int = Field(default=0, description="Word count of content")
    language: str = Field(default="en", description="Content language code")
    site_name: Optional[str] = Field(default=None, description="Source site name")


class ExtractedContent(BaseModel):
    """Content extracted from a URL."""

    url: str = Field(description="Original URL")
    url_type: URLType = Field(description="Detected URL type")
    raw_text: str = Field(description="Extracted text content")
    metadata: ContentMetadata = Field(
        default_factory=ContentMetadata, description="Content metadata"
    )
    extracted_at: datetime = Field(
        default_factory=lambda: datetime.now(timezone.utc), description="Extraction timestamp"
    )
    extraction_method: str = Field(
        default="unknown", description="Method used for extraction"
    )
    fallback_used: bool = Field(
        default=False, description="Whether Wayback fallback was used"
    )


class ProcessingStatus(str, Enum):
    """Status of URL processing."""

    PENDING = "pending"
    EXTRACTING = "extracting"
    FACT_CHECKING = "fact_checking"
    SUMMARIZING = "summarizing"
    COMPLETED = "completed"
    FAILED = "failed"


class ProcessedResult(BaseModel):
    """Complete result of processing a URL."""

    url: str = Field(description="Original URL")
    source_type: URLType = Field(description="Detected source type")
    status: ProcessingStatus = Field(
        default=ProcessingStatus.PENDING, description="Processing status"
    )
    extracted_at: Optional[datetime] = Field(
        default=None, description="When content was extracted"
    )
    content: Optional[ContentMetadata] = Field(
        default=None, description="Content metadata"
    )
    raw_text: Optional[str] = Field(
        default=None, description="Raw extracted text (optional, for debugging)"
    )
    summary: Optional[ContentSummary] = Field(
        default=None, description="Generated summary"
    )
    fact_check: Optional[FactCheckReport] = Field(
        default=None, description="Fact-check results"
    )
    error: Optional[str] = Field(
        default=None, description="Error message if processing failed"
    )
    processing_time_ms: Optional[int] = Field(
        default=None, description="Total processing time in milliseconds"
    )


class SourceReference(BaseModel):
    """Reference to an original source article in an aggregated result."""

    url: str = Field(description="Original article URL")
    title: Optional[str] = Field(default=None, description="Original article title")
    site_name: Optional[str] = Field(default=None, description="Source site name")
    author: Optional[str] = Field(default=None, description="Article author")
    published_date: Optional[datetime] = Field(
        default=None, description="Publication date"
    )
    source_type: URLType = Field(
        default=URLType.UNKNOWN, description="Type of source"
    )


class AggregatedResult(BaseModel):
    """Aggregated result combining multiple similar articles into one entry."""

    title: str = Field(description="Unified title for the aggregated story")
    sources: List[SourceReference] = Field(
        min_length=1, description="All source articles that were merged"
    )
    summary: ContentSummary = Field(
        description="Combined summary with concatenated content from all sources"
    )
    source_type: URLType = Field(
        default=URLType.NEWS_ARTICLE, description="Primary source type"
    )
    status: ProcessingStatus = Field(
        default=ProcessingStatus.COMPLETED, description="Processing status"
    )
    fact_check: Optional[FactCheckReport] = Field(
        default=None, description="Combined fact-check results"
    )
    is_aggregated: bool = Field(
        default=True, description="Flag indicating this is an aggregated result"
    )
    original_count: int = Field(
        default=1, description="Number of original articles merged"
    )


class AggregatedResultSet(BaseModel):
    """Complete set of aggregated results after deduplication."""

    results: List[AggregatedResult] = Field(
        default_factory=list, description="List of aggregated results"
    )
    total_original: int = Field(
        default=0, description="Total number of original articles before aggregation"
    )
    total_aggregated: int = Field(
        default=0, description="Total number of entries after aggregation"
    )
    duplicates_merged: int = Field(
        default=0, description="Number of duplicate groups that were merged"
    )
    aggregated_at: datetime = Field(
        default_factory=lambda: datetime.now(timezone.utc),
        description="When aggregation was performed",
    )


# Request/Response models for API
class URLSubmitRequest(BaseModel):
    """Request to submit URLs for processing."""

    urls: List[str] = Field(
        min_length=1, max_length=100, description="List of URLs to process"
    )
    include_raw_text: bool = Field(
        default=False, description="Include raw extracted text in response"
    )
    skip_fact_check: bool = Field(
        default=False, description="Skip fact-checking step"
    )


class JobStatus(BaseModel):
    """Status of a processing job."""

    job_id: str = Field(description="Unique job identifier")
    status: ProcessingStatus = Field(description="Overall job status")
    total_urls: int = Field(description="Total URLs in the job")
    completed: int = Field(default=0, description="Number of completed URLs")
    failed: int = Field(default=0, description="Number of failed URLs")
    results: List[ProcessedResult] = Field(
        default_factory=list, description="Processing results"
    )
    created_at: datetime = Field(
        default_factory=lambda: datetime.now(timezone.utc), description="Job creation time"
    )
    completed_at: Optional[datetime] = Field(
        default=None, description="Job completion time"
    )


